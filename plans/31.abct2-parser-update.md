# ABCt v2 Parser Update

## Table of Contents

1. [Goal](#goal)
2. [Context and Dependencies](#context-and-dependencies)
3. [Design Decisions](#design-decisions)
4. [Phase 1: AST and Precedence Overhaul (Atomic)](#phase-1-ast-and-precedence-overhaul-atomic)
5. [Phase 2: StringLiteral and AbcLiteral Atoms](#phase-2-stringliteral-and-abcliteral-atoms)
6. [Phase 3: over Expression](#phase-3-over-expression)
7. [Phase 4: Function Definition](#phase-4-function-definition)
8. [Phase 5: Pattern-Matching Function](#phase-5-pattern-matching-function)
9. [Phase 6: Record Literals](#phase-6-record-literals)
10. [Phase 7: load Expression](#phase-7-load-expression)
11. [Phase 8: if/then/else Conditional](#phase-8-ifthenelse-conditional)
12. [Phase 9: Strategy Keywords as Atoms](#phase-9-strategy-keywords-as-atoms)
13. [Phase 10: Error Recovery Updates](#phase-10-error-recovery-updates)
14. [Phase 11: Generator Updates](#phase-11-generator-updates)
15. [Phase 12: Example-Based Tests](#phase-12-example-based-tests)
16. [Phase 13: Property-Based Tests](#phase-13-property-based-tests)
17. [Deferred Work](#deferred-work)
18. [Implementation Checklist](#implementation-checklist)

---

## Goal

We are updating the ABCt parser to produce the AST for the v2 surface syntax. Because the parser is recursive descent with a clean precedence hierarchy, the structural changes are:
- Remove 4 obsolete production rules (Update, Concat, FileRef, VoiceRef)
- Add 8 new production rules (over, fn, fn-match, record, load, if/then/else, string literal, inline ABC literal)
- Simplify the precedence table (two levels disappear)
- Extend the atom dispatch to accept new keyword tokens and literal forms

The parser infrastructure (context class, token utilities, error recovery skeleton) remains unchanged.

---

## Context and Dependencies

### Dependency on plan 30

This plan depends on the scanner updates from plan 30. The scanner must produce the following new tokens before the parser can consume them: `FN`, `MATCH`, `OVER`, `LET`, `IF`, `THEN`, `ELSE`, `TOPDOWN`, `BOTTOMUP`, `ONCETD`, `ALLTD`, `LOAD`, `ARROW`, `LBRACE`, `RBRACE`, `ABC_LITERAL_OPEN`, `ABC_LITERAL_CONTENT`, `ABC_LITERAL_CLOSE`. The scanner must also no longer produce `PIPE_EQ`.

### Source files

- `abct/src/ast.ts` -- AST node interfaces, Expr union, type guards
- `abct/src/parser/expressions.ts` -- precedence-based expression parsing
- `abct/src/parser/atoms.ts` -- atom-level parsing (selectors, lists, groups, etc.)
- `abct/src/parser/parser.ts` -- program/statement parsing, assignment detection
- `abct/src/parser/recovery.ts` -- error recovery and synchronization
- `abct/src/parser/utils.ts` -- token utilities (peek, advance, match, etc.)
- `abct/src/parser/context.ts` -- parser context class

### Test files

- `abct/tests/parser/expressions.spec.ts` -- example-based expression tests
- `abct/tests/pbt.spec.ts` -- property-based grammar tests
- `abct/tests/generators.ts` -- fast-check arbitraries for grammar constructs

---

## Design Decisions

### Match arm body termination

Because `parsePipeline` skips EOL between pipe segments, a naive implementation would let a multi-line arm body consume subsequent arms (e.g., a `|` on the next line would be treated as a pipeline continuation). We solve this by making arm body parsing line-sensitive: the arm body is parsed with a dedicated `parseArmBody()` function that calls `parseApplication` (not `parsePipeline`). If the user wants a pipeline in an arm body, they must parenthesize it:

```
fn rule = match {
  chord |c| => (c | over @notes (transpose 2))
  note |n| => n
}
```

Without parentheses, the arm body is a single application (whitespace-juxtaposed terms on one line). This avoids the ambiguity between a `|` continuing a pipeline and the next arm tag starting.

### `LET` token is not consumed by the parser

The scanner (plan 30) adds a `LET` token because the core IR uses `let x = e; e`. However, the surface syntax uses bare `name = expr` for bindings (same as v1's Assignment). The parser does not consume `LET` — if the user writes `let x = 5`, the parser sees `LET` as an unexpected token and reports an error. The `LET` token is reserved for a future desugarer that might emit core IR directly, or for a REPL mode. The parser plan does not need to handle it.

### `X:1` is handled by the parser, not a special token

Per plan 30's design decisions, `X:1` is tokenized as `IDENTIFIER("X") COLON NUMBER("1")`. The parser handles this in the atom dispatch: when it sees an identifier followed by a colon followed by a number (and the identifier is `"X"`), it produces a tune selector node. This reuses the same lookahead pattern that v1 used for VoiceRef, but with a different resulting AST node.

### `RecordLiteral` avoids TypeScript name collision

The AST interface for record expressions is named `RecordLiteral` (not `Record`) to avoid shadowing TypeScript's built-in utility type `Record<K,V>`.

### `StringLiteral` is a new Expr variant

The existing `Expr` union has no string literal node. Because record fields can have string values (`{name="Trumpet"}`) and `load` takes a string argument, the parser needs to parse `STRING` tokens as atoms that produce `StringLiteral` expression nodes. This is a new addition not in v1.

### The `+` operator is no longer valid

Because the Concat production is removed, the `+` token has no grammatical role in v2. If the parser encounters a `+` token where an atom or operator is expected, it falls through to error recovery. The plan does not repurpose `+`.

### `if/then/else` is greedy inside pipelines

Because `if/then/else` is parsed at the atom level but its sub-expressions (condition, consequent, alternative) are parsed with `parsePipeline`, the alternative branch consumes greedily. For example:

```
source | if cond then a else b | c
```

Parses as: `source | (if cond then a else (b | c))`. The user must parenthesize to limit scope: `source | (if cond then a else b) | c`. This behavior is documented and tested.

### Phases 1 through the precedence change are a single atomic commit

Removing AST types (Phase 1) immediately breaks the TypeScript build because the parser still references them. The removal of parser functions and the precedence rewiring must happen in the same commit. Phase 1 therefore bundles: AST type changes, parser production removal, and precedence simplification.

### Each subsequent phase adds its own atom dispatch case

Phase 1 does not pre-populate the atom dispatch with calls to functions that do not yet exist. Instead, each phase (3 through 9) adds its own entry to the atom dispatch when it implements the corresponding parse function.

### Empty match bodies produce a parser error

A match block with zero arms (`fn x = match {}`) is a parser error: "Expected at least one match arm." The `parseMatchArms` function reports this error and produces an empty arms array with an ErrorExpr.

### `over` focus is restricted to selectors, locations, and identifiers

Although the focus field is typed as `Expr` (to keep the AST simple), the parser calls `parseAtom` for the focus and the semantic analyzer (deferred) will reject non-selector/location values. No parser-level restriction is enforced because an identifier might resolve to a selector function at runtime.

---

## Phase 1: AST and Precedence Overhaul (Atomic)

This phase is a single atomic commit that removes obsolete constructs, adds new AST types, and rewires the precedence chain.

### 1.1 Interfaces to remove from `ast.ts`

Delete the following interfaces and their type guards:

- `Concat` (type: `"concat"`) and `isConcat()`
- `Update` (type: `"update"`) and `isUpdate()`
- `FileRef` (type: `"file_ref"`) and `isFileRef()`
- `VoiceRef` (type: `"voice_ref"`) and `isVoiceRef()`

### 1.2 Interfaces to add to `ast.ts`

```typescript
export interface StringLiteral {
  type: "string";
  value: string;    // content without quotes
  loc: Loc;
}

export interface AbcLiteralInline {
  type: "abc_literal_inline";
  content: string;  // the ABC text between backticks
  loc: Loc;
}

export interface OverExpr {
  type: "over";
  kwLoc: Loc;
  focus: Expr;
  body: Expr;
  openLoc: Loc;     // location of '('
  closeLoc: Loc;    // location of ')'
  loc: Loc;
}

export interface FnDef {
  type: "fn_def";
  kwLoc: Loc;
  name: string;
  nameLoc: Loc;
  params: FnParam[];
  openParenLoc: Loc;
  closeParenLoc: Loc;
  openBraceLoc: Loc;
  closeBraceLoc: Loc;
  body: Expr;
  loc: Loc;
}

export interface FnParam {
  name: string;
  loc: Loc;
}

export interface FnMatchDef {
  type: "fn_match_def";
  kwLoc: Loc;
  name: string;
  nameLoc: Loc;
  eqLoc: Loc;
  matchKwLoc: Loc;
  openBraceLoc: Loc;
  closeBraceLoc: Loc;
  arms: MatchArm[];
  loc: Loc;
}

export interface MatchArm {
  tag: string;
  tagLoc: Loc;
  capture?: CaptureBinding;
  guardIfLoc?: Loc;   // location of the 'if' keyword in the guard
  guard?: Expr;
  arrowLoc: Loc;
  body: Expr;
  loc: Loc;
}

export interface CaptureBinding {
  name: string;
  nameLoc: Loc;
  openPipeLoc: Loc;
  closePipeLoc: Loc;
}

export interface RecordLiteral {
  type: "record";
  fields: RecordField[];
  openLoc: Loc;
  closeLoc: Loc;
  loc: Loc;
}

export interface RecordField {
  key: string;
  keyLoc: Loc;
  eqLoc: Loc;
  value: Expr;
  loc: Loc;
}

export interface LoadExpr {
  type: "load";
  kwLoc: Loc;
  path: string;
  pathLoc: Loc;
  loc: Loc;
}

export interface IfExpr {
  type: "if";
  ifLoc: Loc;
  condition: Expr;
  thenLoc: Loc;
  consequent: Expr;
  elseLoc: Loc;
  alternative: Expr;
  loc: Loc;
}

export interface TuneSelector {
  type: "tune_selector";
  tuneNumber: number;
  loc: Loc;
}
```

### 1.3 Update the Expr union

Remove `Concat`, `Update`, `FileRef`, `VoiceRef`. Add the new types:

```typescript
export type Expr =
  | Pipe
  | Application
  | Or
  | And
  | Not
  | Negate
  | Comparison
  | FilterExpression
  | Selector
  | LocationSelector
  | TuneSelector
  | List
  | AbcLiteral
  | AbcLiteralInline
  | StringLiteral
  | NumberLiteral
  | Identifier
  | Group
  | OverExpr
  | RecordLiteral
  | LoadExpr
  | IfExpr
  | ErrorExpr;
```

### 1.4 Update the Statement type

```typescript
export type Statement = Assignment | FnDef | FnMatchDef | Expr;
```

### 1.5 Type guards to add

One `is*` function per new node type: `isStringLiteral`, `isAbcLiteralInline`, `isOverExpr`, `isFnDef`, `isFnMatchDef`, `isRecordLiteral`, `isLoadExpr`, `isIfExpr`, `isTuneSelector`.

### 1.6 Remove obsolete parser productions

In `expressions.ts`:
- Delete `parseConcatTerm()` entirely
- Delete `parseUpdateTerm()` entirely
- Remove the pipe-equals lookahead in `parsePipeline()` (the check that breaks out when `|` is followed by `=`)

In `atoms.ts`:
- Delete `parseFileRef()` and the `isFileRef()` lookahead helper
- Delete `parseVoiceRef()` and the `isVoiceRef()` lookahead helper
- Delete `parseLocationValue()` (only used by `parseFileRef`)
- Remove the corresponding cases from the atom dispatch

### 1.7 Simplify precedence chain

After removal, the call chain becomes:

```
parsePipeline()     -> calls parseApplication()  (was parseConcatTerm)
parseApplication()  -> calls parseOr()           (unchanged)
parseOr()           -> calls parseAnd()          (unchanged)
parseAnd()          -> calls parseNot()          (unchanged)
parseNot()          -> calls parseComparison()   (unchanged)
parseComparison()   -> calls parseAtom()         (unchanged, unary minus is inside parseAtom)
```

Note: the existing code has `parseComparison` calling `parseAtom` directly (unary minus is handled inside the atom dispatch, not as a separate precedence level). The precedence table in this plan reflects the actual code structure.

### 1.8 Delete existing tests that reference removed types

Delete or update all test cases in `expressions.spec.ts` that use `isConcat`, `isUpdate`, `isFileRef`, `isVoiceRef`. Delete the corresponding imports.

---

## Phase 2: StringLiteral and AbcLiteral Atoms

### 2.1 Rationale

The scanner produces `STRING` tokens and `ABC_LITERAL_OPEN/CONTENT/CLOSE` token sequences. The parser needs to handle both as atoms.

### 2.2 StringLiteral

In the atom dispatch, when the current token is `AbctTT.STRING`:

```
token = advance(ctx)
value = token.lexeme.slice(1, -1)   // strip quotes
return StringLiteral { value, loc: tokenToLoc(token) }
```

### 2.3 AbcLiteralInline

In the atom dispatch, when the current token is `AbctTT.ABC_LITERAL_OPEN`:

```
openToken = advance(ctx)   // consume opening backtick
content = ""
if check(ctx, AbctTT.ABC_LITERAL_CONTENT):
  contentToken = advance(ctx)
  content = contentToken.lexeme
if check(ctx, AbctTT.ABC_LITERAL_CLOSE):
  closeToken = advance(ctx)
else:
  error("Unterminated inline ABC literal")
return AbcLiteralInline { content, loc: spanLoc(openToken, closeToken or contentToken) }
```

### 2.4 TuneSelector

In the atom dispatch, add a lookahead for the `X:number` pattern. When the current token is `IDENTIFIER` with lexeme `"X"`, followed by `COLON`, followed by `NUMBER`:

```
if peek(ctx).lexeme == "X" and peekAt(ctx, +1) is COLON and peekAt(ctx, +2) is NUMBER:
  xToken = advance(ctx)      // consume "X"
  advance(ctx)               // consume ":"
  numToken = advance(ctx)    // consume number
  return TuneSelector { tuneNumber: parseInt(numToken.lexeme), loc: spanLoc(xToken, numToken) }
```

This lookahead must come before the general identifier case in the atom dispatch. The `peekAt` utility (peeking N tokens ahead, skipping WS) may need to be added to `utils.ts` if it does not already exist.

### 2.5 Update canStartAtom

Add `AbctTT.STRING` and `AbctTT.ABC_LITERAL_OPEN` to the set of tokens that can start an atom.

---

## Phase 3: over Expression

### 3.1 Grammar

```
over_expr := OVER focus LPAREN pipeline RPAREN
focus     := atom
```

### 3.2 Implementation

Add `parseOver()` to `atoms.ts`:

```
parseOver(ctx):
  kwToken = consume(ctx, AbctTT.OVER)
  skipWS(ctx)
  focus = parseAtom(ctx)
  skipWS(ctx)
  openToken = consume(ctx, AbctTT.LPAREN, "Expected '(' after focus in 'over' expression")
  skipWSAndEOL(ctx)
  body = parsePipeline(ctx)
  skipWSAndEOL(ctx)
  closeToken = consume(ctx, AbctTT.RPAREN, "Expected ')' to close 'over' body")
  return OverExpr node
```

### 3.3 Atom dispatch

Add to the atom dispatch: when current token is `AbctTT.OVER`, call `parseOver(ctx)`. Also add `AbctTT.OVER` to `canStartAtom`.

### 3.4 Error cases

- Missing focus: `parseAtom` will report an error if it encounters an unexpected token.
- Missing `(`: report "Expected '(' after focus in 'over' expression"
- Missing `)`: report "Expected ')' to close 'over' body"

---

## Phase 4: Function Definition

### 4.1 Grammar

```
fn_def := FN IDENTIFIER LPAREN param_list RPAREN LBRACE pipeline RBRACE
param_list := (IDENTIFIER (COMMA IDENTIFIER)*)?
```

### 4.2 Detection in parseStatement

In `parseStatement()`, before the assignment lookahead, check whether the current token is `FN`. If so, call `parseFnStatement(ctx)`.

`parseFnStatement` does not consume any tokens. It uses positional lookahead (peeking past FN, WS, IDENTIFIER, WS) to determine whether the next significant token is `LPAREN` (fn def) or `EQ` (fn match def), then dispatches to the appropriate function which consumes from the `FN` token onward:

```
parseFnStatement(ctx):
  // Peek ahead: FN WS? IDENTIFIER WS? (LPAREN | EQ)
  savedPos = ctx.current
  // Find the token after FN + name
  fnPos = ctx.current          // at FN
  namePos = next non-WS after fnPos
  afterNamePos = next non-WS after namePos
  if token at afterNamePos is LPAREN:
    return parseFnDef(ctx)     // starts consuming from FN
  if token at afterNamePos is EQ:
    return parseFnMatchDef(ctx)  // starts consuming from FN
  error("Expected '(' or '=' after function name")
  return ErrorExpr
```

### 4.3 parseFnDef implementation

```
parseFnDef(ctx):
  kwToken = consume(ctx, AbctTT.FN)
  skipWS(ctx)
  nameToken = consume(ctx, AbctTT.IDENTIFIER)
  skipWS(ctx)
  openParen = consume(ctx, AbctTT.LPAREN)
  params = parseParamList(ctx)
  closeParen = consume(ctx, AbctTT.RPAREN)
  skipWSAndEOL(ctx)
  openBrace = consume(ctx, AbctTT.LBRACE, "Expected '{' to open function body")
  skipWSAndEOL(ctx)
  body = parsePipeline(ctx)
  skipWSAndEOL(ctx)
  closeBrace = consume(ctx, AbctTT.RBRACE, "Expected '}' to close function body")
  return FnDef node

parseParamList(ctx):
  params = []
  skipWS(ctx)
  if check(ctx, AbctTT.RPAREN): return params
  params.push({ name: consume(IDENTIFIER).lexeme, loc })
  while match(ctx, AbctTT.COMMA):
    skipWS(ctx)
    params.push({ name: consume(IDENTIFIER).lexeme, loc })
  return params
```

The function body is a single pipeline expression (not a statement block). The body is parenthesized by `{ }`, so `parsePipeline` naturally stops at the closing `}`.

---

## Phase 5: Pattern-Matching Function

### 5.1 Grammar

```
fn_match_def := FN IDENTIFIER EQ MATCH LBRACE match_arm+ RBRACE
match_arm    := IDENTIFIER capture? guard? ARROW arm_body EOL
capture      := PIPE IDENTIFIER PIPE
guard        := IF pipeline
arm_body     := application | group
```

### 5.2 Disambiguation of `|` as capture vs. pipe

Inside a match arm, after the tag identifier, if we see a `PIPE` token followed by an `IDENTIFIER` followed by another `PIPE`, we parse it as a capture binding. This is unambiguous because at this position (before `=>` or `if`), no left-hand operand has been accumulated for a pipeline.

### 5.3 Arm body termination

The arm body is parsed with `parseApplication(ctx)` (NOT `parsePipeline`). This means a bare `|` on the same line would not be consumed as a pipe — it would be an unexpected token. If the user wants a pipeline in the arm body, they must parenthesize it:

```
chord |c| => (c | transpose 2)
```

Because `parseApplication` calls `parseAtom` which handles groups `(expr)`, the parenthesized pipeline is parsed correctly by `parseGroup`, which internally calls `parsePipeline`.

### 5.4 parseFnMatchDef implementation

```
parseFnMatchDef(ctx):
  kwToken = consume(ctx, AbctTT.FN)
  skipWS(ctx)
  nameToken = consume(ctx, AbctTT.IDENTIFIER)
  skipWS(ctx)
  eqToken = consume(ctx, AbctTT.EQ)
  skipWS(ctx)
  matchKwToken = consume(ctx, AbctTT.MATCH)
  skipWSAndEOL(ctx)
  openBrace = consume(ctx, AbctTT.LBRACE)
  arms = parseMatchArms(ctx)
  closeBrace = consume(ctx, AbctTT.RBRACE)
  return FnMatchDef node

parseMatchArms(ctx):
  arms = []
  loop:
    skipWSAndEOL(ctx)
    if check(ctx, AbctTT.RBRACE): break
    if isAtEnd(ctx): break
    arms.push(parseMatchArm(ctx))
  if arms.length == 0:
    error("Expected at least one match arm")
  return arms

parseMatchArm(ctx):
  tagToken = consume(ctx, AbctTT.IDENTIFIER)
  skipWS(ctx)
  capture = null
  if check(ctx, AbctTT.PIPE):
    capture = parseCapture(ctx)
    skipWS(ctx)
  guardIfLoc = null
  guard = null
  if check(ctx, AbctTT.IF):
    ifToken = advance(ctx)
    guardIfLoc = tokenToLoc(ifToken)
    skipWS(ctx)
    guard = parseApplication(ctx)  // guard is an application, not a full pipeline
    skipWS(ctx)
  arrowToken = consume(ctx, AbctTT.ARROW, "Expected '=>' in match arm")
  skipWS(ctx)
  body = parseApplication(ctx)     // arm body is an application (parenthesize for pipeline)
  return MatchArm node

parseCapture(ctx):
  openPipe = consume(ctx, AbctTT.PIPE)
  skipWS(ctx)
  nameToken = consume(ctx, AbctTT.IDENTIFIER, "Expected capture variable name")
  skipWS(ctx)
  closePipe = consume(ctx, AbctTT.PIPE, "Expected closing '|' for capture")
  return CaptureBinding node
```

---

## Phase 6: Record Literals

### 6.1 Grammar

```
record := LBRACE field_list? RBRACE
field_list := field (COMMA field)* COMMA?
field := IDENTIFIER EQ atom
```

Trailing commas are allowed (the parser consumes an optional comma after the last field before checking for `}`).

### 6.2 Disambiguation from match/fn bodies

There is no ambiguity because match and fn body `{` tokens are always consumed by their respective parse functions (`parseFnMatchDef`, `parseFnDef`) immediately after their preceding keyword/delimiter. The atom dispatch only encounters `{` when it has not been consumed by a parent production.

### 6.3 parseRecord implementation

Add to `atoms.ts`:

```
parseRecord(ctx):
  openBrace = consume(ctx, AbctTT.LBRACE)
  skipWSAndEOL(ctx)
  fields = []
  if not check(ctx, AbctTT.RBRACE):
    fields.push(parseRecordField(ctx))
    while true:
      skipWSAndEOL(ctx)
      if not match(ctx, AbctTT.COMMA): break
      skipWSAndEOL(ctx)
      if check(ctx, AbctTT.RBRACE): break   // trailing comma
      fields.push(parseRecordField(ctx))
  skipWSAndEOL(ctx)
  closeBrace = consume(ctx, AbctTT.RBRACE, "Expected '}' to close record")
  return RecordLiteral node

parseRecordField(ctx):
  keyToken = consume(ctx, AbctTT.IDENTIFIER, "Expected field name")
  skipWS(ctx)
  eqToken = consume(ctx, AbctTT.EQ, "Expected '=' after field name")
  skipWS(ctx)
  value = parseAtom(ctx)   // value is any atom (identifier, number, string, list, etc.)
  return RecordField node
```

### 6.4 Atom dispatch and canStartAtom

Add `AbctTT.LBRACE` to `canStartAtom`. Add case in atom dispatch: when current token is `LBRACE`, call `parseRecord(ctx)`.

---

## Phase 7: load Expression

### 7.1 Grammar

```
load_expr := LOAD STRING
```

### 7.2 Implementation

Add to `atoms.ts`:

```
parseLoad(ctx):
  kwToken = consume(ctx, AbctTT.LOAD)
  skipWS(ctx)
  pathToken = consume(ctx, AbctTT.STRING, "Expected file path string after 'load'")
  path = pathToken.lexeme.slice(1, -1)   // strip quotes
  return LoadExpr node
```

### 7.3 Atom dispatch and canStartAtom

Add `AbctTT.LOAD` to `canStartAtom`. Add case in atom dispatch: when current token is `LOAD`, call `parseLoad(ctx)`.

---

## Phase 8: if/then/else Conditional

### 8.1 Grammar

```
if_expr := IF pipeline THEN pipeline ELSE pipeline
```

### 8.2 Greediness behavior

Because the sub-expressions are parsed with `parsePipeline`, the alternative branch is greedy. In `source | if cond then a else b | c`, the parse result is `source | (if cond then a else (b | c))`. The user must parenthesize to limit: `source | (if cond then a else b) | c`.

### 8.3 Implementation

Add to `atoms.ts`:

```
parseIf(ctx):
  ifToken = consume(ctx, AbctTT.IF)
  skipWS(ctx)
  condition = parsePipeline(ctx)
  skipWSAndEOL(ctx)
  thenToken = consume(ctx, AbctTT.THEN, "Expected 'then' after condition")
  skipWS(ctx)
  consequent = parsePipeline(ctx)
  skipWSAndEOL(ctx)
  elseToken = consume(ctx, AbctTT.ELSE, "Expected 'else' after consequent")
  skipWS(ctx)
  alternative = parsePipeline(ctx)
  return IfExpr node
```

### 8.4 Atom dispatch and canStartAtom

Add `AbctTT.IF` to `canStartAtom`. Add case in atom dispatch: when current token is `IF`, call `parseIf(ctx)`.

### 8.5 Interaction with Application

Because `if` is an atom and `parseApplication` collects multiple atoms by juxtaposition, the expression `transpose if cond then @chords else @notes 2` parses as `Application(transpose, if(...), 2)`. The `if` atom consumes greedily up to the end of the else branch. The `2` becomes a separate application term. This is correct for verb-first syntax but may surprise users; they should write `transpose (if cond then @chords else @notes) 2` if they want the `2` to be part of the else branch.

---

## Phase 9: Strategy Keywords as Atoms

### 9.1 Rationale

`topdown`, `bottomup`, `oncetd`, `alltd` are keywords that function as identifiers in application position. For example, `topdown my_rule` parses as `Application(Identifier("topdown"), Identifier("my_rule"))`. Because the scanner produces distinct token types for these keywords (not `IDENTIFIER`), the atom dispatch must handle them explicitly.

### 9.2 Implementation

In the atom dispatch, add cases for the strategy tokens:

```
case AbctTT.TOPDOWN:
case AbctTT.BOTTOMUP:
case AbctTT.ONCETD:
case AbctTT.ALLTD:
  token = advance(ctx)
  return Identifier { name: token.lexeme, loc: tokenToLoc(token) }
```

### 9.3 canStartAtom

Add `AbctTT.TOPDOWN`, `AbctTT.BOTTOMUP`, `AbctTT.ONCETD`, `AbctTT.ALLTD` to `canStartAtom`.

### 9.4 Interaction with pipes

`topdown | my_rule` parses as `Pipe(Identifier("topdown"), Identifier("my_rule"))` because `|` is handled by `parsePipeline`, which is above `parseApplication` in precedence. The strategy keyword is a standalone atom on the left of the pipe. This is valid syntax (though semantically different from `topdown my_rule` which is an application).

---

## Phase 10: Error Recovery Updates

### 10.1 Location

`abct/src/parser/recovery.ts`

### 10.2 Add brace recovery points

Add `AbctTT.LBRACE` and `AbctTT.RBRACE` to the recovery point set used by `isAtRecoveryPoint()`. These are natural recovery boundaries for record literals, match bodies, and fn bodies.

### 10.3 Match arm recovery

For errors inside a match arm, recovery should advance to the next `ARROW` (start of the arm body) or `RBRACE` (end of the match block). Implement this as a `synchronizeMatchArm(ctx)` function that advances until it finds `AbctTT.ARROW`, `AbctTT.RBRACE`, or EOF. Call it from `parseMatchArm` when an error occurs (e.g., missing capture close, unexpected token before `=>`).

### 10.4 Missing closing delimiter recovery

For `parseRecord`, `parseFnDef`, and `parseFnMatchDef`, if the closing `}` is missing, the `consume` call will report the error. Add a `synchronizeToClose(ctx, AbctTT.RBRACE)` fallback that advances to the next `}` or EOF, to prevent cascading errors.

### 10.5 Remove PIPE_EQ references

If any recovery logic references `AbctTT.PIPE_EQ`, remove those cases.

---

## Phase 11: Generator Updates

### 11.1 Location

`abct/tests/generators.ts`

### 11.2 Remove obsolete generators

Delete: `genUpdate`, `genLocationUpdate`, `genPipelineWithLocationUpdate`, `genSimpleConcat`, `genFileCombination`, `genFileRef`, `genPath`, `genPathWithDir`, `genSelectorPath` (path-style, used by FileRef).

### 11.3 New generators

```typescript
export const genStringLiteral: fc.Arbitrary<string> = fc
  .stringMatching(/^[a-zA-Z0-9 _,.!?]{0,15}$/)
  .map((s) => `"${s}"`);

export const genAbcLiteralInline: fc.Arbitrary<string> = fc
  .stringMatching(/^[A-Ga-g0-9 |[\]]{0,15}$/)
  .map((content) => "`" + content + "`");

export const genOver: fc.Arbitrary<string> = fc
  .tuple(
    fc.oneof(genSelector, genLocationSelector),
    genSimpleAtom
  )
  .map(([focus, body]) => `over ${focus} (${body})`);

export const genFnDef: fc.Arbitrary<string> = fc
  .tuple(
    genIdentifier,
    fc.array(genIdentifier, { minLength: 0, maxLength: 3 }),
    genSimpleAtom
  )
  .map(([name, params, body]) =>
    `fn ${name}(${params.join(", ")}) { ${body} }`
  );

export const genMatchArm: fc.Arbitrary<string> = fc
  .tuple(
    genIdentifier,
    fc.option(genIdentifier),
    genSimpleAtom
  )
  .map(([tag, capture, body]) => {
    const capStr = capture ? ` |${capture}|` : "";
    return `  ${tag}${capStr} => ${body}`;
  });

export const genFnMatchDef: fc.Arbitrary<string> = fc
  .tuple(
    genIdentifier,
    fc.array(genMatchArm, { minLength: 1, maxLength: 3 })
  )
  .map(([name, arms]) =>
    `fn ${name} = match {\n${arms.join("\n")}\n}`
  );

export const genRecord: fc.Arbitrary<string> = fc
  .array(
    fc.tuple(genIdentifier, fc.oneof(genIdentifier, genNumber, genStringLiteral))
      .map(([k, v]) => `${k}=${v}`),
    { minLength: 0, maxLength: 4 }
  )
  .map((fields) => `{${fields.join(", ")}}`);

export const genLoad: fc.Arbitrary<string> = fc
  .stringMatching(/^[a-zA-Z_][a-zA-Z0-9_]{0,8}\.(abc|abct)$/)
  .map((path) => `load "${path}"`);

export const genIfExpr: fc.Arbitrary<string> = fc
  .tuple(genSimpleAtom, genSimpleAtom, genSimpleAtom)
  .map(([cond, cons, alt]) => `if ${cond} then ${cons} else ${alt}`);

export const genStrategyApp: fc.Arbitrary<string> = fc
  .tuple(
    fc.constantFrom("topdown", "bottomup", "oncetd", "alltd"),
    genIdentifier
  )
  .map(([strat, rule]) => `${strat} ${rule}`);

export const genTuneSelector: fc.Arbitrary<string> = fc
  .integer({ min: 1, max: 99 })
  .map((n) => `X:${n}`);
```

### 11.4 Update genSimpleAtom

Add `genRecord`, `genStringLiteral`, `genAbcLiteralInline`, `genTuneSelector` to the `genSimpleAtom` oneof.

### 11.5 Update genExpr

Remove obsolete entries. Add new ones:

```typescript
export const genExpr: fc.Arbitrary<string> = fc.oneof(
  { weight: 5, arbitrary: genSimpleAtom },
  { weight: 2, arbitrary: genApplication },
  { weight: 2, arbitrary: genComparison },
  { weight: 2, arbitrary: genOver },
  { weight: 1, arbitrary: genIfExpr },
  { weight: 1, arbitrary: genStrategyApp },
  { weight: 1, arbitrary: genSimplePipe },
  { weight: 1, arbitrary: genParenExpr },
  { weight: 1, arbitrary: genNotExpr },
  { weight: 1, arbitrary: genAndExpr },
  { weight: 1, arbitrary: genOrExpr },
  { weight: 1, arbitrary: genLoad }
);
```

### 11.6 Update genStatement

```typescript
export const genStatement: fc.Arbitrary<string> = fc.oneof(
  { weight: 1, arbitrary: genAssignment },
  { weight: 1, arbitrary: genFnDef },
  { weight: 1, arbitrary: genFnMatchDef },
  { weight: 3, arbitrary: genExpr }
);
```

### 11.7 Update genIdentifier filter

Use the complete keyword exclusion set (all 16 keywords from plan 30):

```typescript
const KEYWORDS = new Set([
  "and", "or", "not", "filter",
  "fn", "match", "over", "let", "if", "then", "else",
  "topdown", "bottomup", "oncetd", "alltd", "load"
]);

export const genIdentifier: fc.Arbitrary<string> = fc
  .stringMatching(/^[a-zA-Z_][a-zA-Z0-9_]{0,8}$/)
  .filter((id) => !KEYWORDS.has(id) && id.length > 0);
```

---

## Phase 12: Example-Based Tests

### 12.1 Location

`abct/tests/parser/expressions.spec.ts`

### 12.2 String and inline ABC literal tests

```typescript
it("should parse a string literal", () => {
  const { expr, errors } = parse('"hello"');
  expect(isStringLiteral(expr)).to.be.true;
  if (isStringLiteral(expr)) expect(expr.value).to.equal("hello");
  expect(errors).to.have.length(0);
});

it("should parse an inline ABC literal", () => {
  const { expr, errors } = parse("`CEG A2`");
  expect(isAbcLiteralInline(expr)).to.be.true;
  if (isAbcLiteralInline(expr)) expect(expr.content).to.equal("CEG A2");
  expect(errors).to.have.length(0);
});

it("should parse X:1 as tune selector", () => {
  const { expr, errors } = parse("X:1");
  expect(isTuneSelector(expr)).to.be.true;
  if (isTuneSelector(expr)) expect(expr.tuneNumber).to.equal(1);
  expect(errors).to.have.length(0);
});
```

### 12.3 over tests

```typescript
it("should parse 'over @chords (transpose 2)'", () => {
  const { expr, errors } = parse("over @chords (transpose 2)");
  expect(isOverExpr(expr)).to.be.true;
  if (isOverExpr(expr)) {
    expect(isSelector(expr.focus)).to.be.true;
    expect(isApplication(expr.body)).to.be.true;
  }
  expect(errors).to.have.length(0);
});

it("should parse 'over :5:1-8 (remove)'", () => {
  const { expr, errors } = parse("over :5:1-8 (remove)");
  expect(isOverExpr(expr)).to.be.true;
  if (isOverExpr(expr)) expect(isLocationSelector(expr.focus)).to.be.true;
  expect(errors).to.have.length(0);
});

it("should parse over in a pipeline", () => {
  const { expr, errors } = parse("source | over @chords (transpose 2)");
  expect(isPipe(expr)).to.be.true;
  expect(errors).to.have.length(0);
});

it("should parse nested over", () => {
  const { expr, errors } = parse("over @chords (over :1:5 (transpose 2))");
  expect(isOverExpr(expr)).to.be.true;
  if (isOverExpr(expr)) expect(isOverExpr(expr.body)).to.be.true;
  expect(errors).to.have.length(0);
});

it("should error on over without parens", () => {
  const { errors } = parse("over @chords transpose 2");
  expect(errors.length).to.be.greaterThan(0);
});
```

### 12.4 fn tests

```typescript
it("should parse 'fn double(x) { x }'", () => {
  const result = parseStmt("fn double(x) { x }");
  expect(isFnDef(result.stmt)).to.be.true;
  if (isFnDef(result.stmt)) {
    expect(result.stmt.name).to.equal("double");
    expect(result.stmt.params).to.have.length(1);
  }
});

it("should parse fn with no params", () => {
  const result = parseStmt("fn reset() { source }");
  expect(isFnDef(result.stmt)).to.be.true;
  if (isFnDef(result.stmt)) expect(result.stmt.params).to.have.length(0);
});

it("should parse fn with multi-line body", () => {
  const result = parseStmt("fn process(x) {\n  x | transpose 2\n}");
  expect(isFnDef(result.stmt)).to.be.true;
  if (isFnDef(result.stmt)) expect(isPipe(result.stmt.body)).to.be.true;
});
```

### 12.5 fn match tests

```typescript
it("should parse fn match with capture", () => {
  const result = parseStmt("fn my_rule = match {\n  chord |c| => c\n}");
  expect(isFnMatchDef(result.stmt)).to.be.true;
  if (isFnMatchDef(result.stmt)) {
    expect(result.stmt.arms).to.have.length(1);
    expect(result.stmt.arms[0].capture?.name).to.equal("c");
  }
});

it("should parse fn match with guard", () => {
  const src = "fn my_rule = match {\n  chord |c| if length >= 4 => c\n}";
  const result = parseStmt(src);
  expect(isFnMatchDef(result.stmt)).to.be.true;
  if (isFnMatchDef(result.stmt)) {
    expect(result.stmt.arms[0].guard).to.not.be.undefined;
    expect(result.stmt.arms[0].guardIfLoc).to.not.be.undefined;
  }
});

it("should parse fn match with multiple arms", () => {
  const src = "fn voicing = match {\n  chord |c| => c\n  note |n| => n\n}";
  const result = parseStmt(src);
  expect(isFnMatchDef(result.stmt)).to.be.true;
  if (isFnMatchDef(result.stmt)) expect(result.stmt.arms).to.have.length(2);
});

it("should parse match arm without capture or guard", () => {
  const src = "fn passthrough = match {\n  note => transpose 2\n}";
  const result = parseStmt(src);
  expect(isFnMatchDef(result.stmt)).to.be.true;
  if (isFnMatchDef(result.stmt)) {
    expect(result.stmt.arms[0].capture).to.be.undefined;
    expect(result.stmt.arms[0].guard).to.be.undefined;
  }
});

it("should parse match arm with parenthesized pipeline body", () => {
  const src = "fn rule = match {\n  chord |c| => (c | transpose 2)\n}";
  const result = parseStmt(src);
  expect(isFnMatchDef(result.stmt)).to.be.true;
  if (isFnMatchDef(result.stmt)) expect(isGroup(result.stmt.arms[0].body)).to.be.true;
});

it("should error on empty match body", () => {
  const result = parseStmt("fn bad = match {}");
  expect(result.errors.length).to.be.greaterThan(0);
});
```

### 12.6 Record tests

```typescript
it("should parse empty record", () => {
  const { expr, errors } = parse("{}");
  expect(isRecordLiteral(expr)).to.be.true;
  if (isRecordLiteral(expr)) expect(expr.fields).to.have.length(0);
  expect(errors).to.have.length(0);
});

it("should parse record with mixed value types", () => {
  const { expr, errors } = parse('{name="Trumpet", clef=treble, transpose=-2}');
  expect(isRecordLiteral(expr)).to.be.true;
  if (isRecordLiteral(expr)) {
    expect(expr.fields).to.have.length(3);
    expect(isStringLiteral(expr.fields[0].value)).to.be.true;
    expect(isIdentifier(expr.fields[1].value)).to.be.true;
    expect(isNegate(expr.fields[2].value)).to.be.true;
  }
  expect(errors).to.have.length(0);
});

it("should parse record with trailing comma", () => {
  const { expr, errors } = parse("{x=1, y=2,}");
  expect(isRecordLiteral(expr)).to.be.true;
  if (isRecordLiteral(expr)) expect(expr.fields).to.have.length(2);
  expect(errors).to.have.length(0);
});
```

### 12.7 load tests

```typescript
it("should parse 'load \"file.abc\"'", () => {
  const { expr, errors } = parse('load "file.abc"');
  expect(isLoadExpr(expr)).to.be.true;
  if (isLoadExpr(expr)) expect(expr.path).to.equal("file.abc");
  expect(errors).to.have.length(0);
});

it("should error on load without string", () => {
  const { errors } = parse("load something");
  expect(errors.length).to.be.greaterThan(0);
});
```

### 12.8 if/then/else tests

```typescript
it("should parse 'if x then y else z'", () => {
  const { expr, errors } = parse("if x then y else z");
  expect(isIfExpr(expr)).to.be.true;
  if (isIfExpr(expr)) {
    expect(isIdentifier(expr.condition)).to.be.true;
    expect(isIdentifier(expr.consequent)).to.be.true;
    expect(isIdentifier(expr.alternative)).to.be.true;
  }
  expect(errors).to.have.length(0);
});

it("should parse if with pipeline bodies (greedy alternative)", () => {
  const { expr, errors } = parse("if cond then a else b | c");
  expect(isIfExpr(expr)).to.be.true;
  if (isIfExpr(expr)) expect(isPipe(expr.alternative)).to.be.true;
  expect(errors).to.have.length(0);
});

it("should parse nested if/then/else (else binds to inner)", () => {
  const { expr, errors } = parse("if a then if b then c else d else e");
  expect(isIfExpr(expr)).to.be.true;
  if (isIfExpr(expr)) {
    expect(isIfExpr(expr.consequent)).to.be.true;
    expect(isIdentifier(expr.alternative)).to.be.true;
    if (isIdentifier(expr.alternative)) expect(expr.alternative.name).to.equal("e");
  }
  expect(errors).to.have.length(0);
});

it("should parse if inside pipeline", () => {
  const { expr, errors } = parse("source | if cond then a else b");
  expect(isPipe(expr)).to.be.true;
  expect(errors).to.have.length(0);
});

it("should error on if without else", () => {
  const { errors } = parse("if x then y");
  expect(errors.length).to.be.greaterThan(0);
});
```

### 12.9 Strategy keyword tests

```typescript
it("should parse 'topdown my_rule' as application", () => {
  const { expr, errors } = parse("topdown my_rule");
  expect(isApplication(expr)).to.be.true;
  if (isApplication(expr)) {
    expect(isIdentifier(expr.terms[0])).to.be.true;
    if (isIdentifier(expr.terms[0])) expect(expr.terms[0].name).to.equal("topdown");
  }
  expect(errors).to.have.length(0);
});

it("should parse 'topdown | my_rule' as pipe (not application)", () => {
  const { expr, errors } = parse("topdown | my_rule");
  expect(isPipe(expr)).to.be.true;
  expect(errors).to.have.length(0);
});
```

### 12.10 Removal verification tests

```typescript
it("should NOT parse 'x |= y' as update (|= is gone)", () => {
  // Scanner no longer produces PIPE_EQ; this is now PIPE followed by EQ
  // which means: pipe to "= y" which is invalid
  const { errors } = parse("x |= y");
  expect(errors.length).to.be.greaterThan(0);
});

it("should NOT parse 'a + b' as concat (+ has no role)", () => {
  const { errors } = parse("a + b");
  expect(errors.length).to.be.greaterThan(0);
});
```

---

## Phase 13: Property-Based Tests

### 13.1 Location

`abct/tests/pbt.spec.ts`

### 13.2 Individual construct properties

```typescript
it("property: generated over expressions parse without errors", () => {
  fc.assert(fc.property(genOver, (src) => parseSource(src).success), { numRuns: 5000 });
});

it("property: generated fn definitions parse without errors", () => {
  fc.assert(fc.property(genFnDef, (src) => parseSource(src).success), { numRuns: 5000 });
});

it("property: generated fn match definitions parse without errors", () => {
  fc.assert(fc.property(genFnMatchDef, (src) => parseSource(src).success), { numRuns: 3000 });
});

it("property: generated records parse without errors", () => {
  fc.assert(fc.property(genRecord, (src) => parseSource(src).success), { numRuns: 5000 });
});

it("property: generated load expressions parse without errors", () => {
  fc.assert(fc.property(genLoad, (src) => parseSource(src).success), { numRuns: 5000 });
});

it("property: generated if expressions parse without errors", () => {
  fc.assert(fc.property(genIfExpr, (src) => parseSource(src).success), { numRuns: 5000 });
});

it("property: generated strategy applications parse without errors", () => {
  fc.assert(fc.property(genStrategyApp, (src) => parseSource(src).success), { numRuns: 5000 });
});

it("property: generated tune selectors parse without errors", () => {
  fc.assert(fc.property(genTuneSelector, (src) => parseSource(src).success), { numRuns: 1000 });
});

it("property: generated string literals parse without errors", () => {
  fc.assert(fc.property(genStringLiteral, (src) => parseSource(src).success), { numRuns: 5000 });
});

it("property: generated inline ABC literals parse without errors", () => {
  fc.assert(fc.property(genAbcLiteralInline, (src) => parseSource(src).success), { numRuns: 5000 });
});
```

### 13.3 Integration property

```typescript
it("property: all generated programs parse without errors", () => {
  fc.assert(fc.property(genProgram, (src) => parseSource(src).success), { numRuns: 10000 });
});
```

### 13.4 Precedence properties

```typescript
it("property: 'atom | over sel (body)' parses as Pipe", () => {
  fc.assert(
    fc.property(genIdentifier, genSelector, genSimpleAtom, (left, sel, body) => {
      const src = `${left} | over ${sel} (${body})`;
      const result = parseSource(src);
      return result.success && isPipe(result.value.statements[0]);
    }),
    { numRuns: 5000 }
  );
});

it("property: 'if a then b else c' always produces IfExpr at top level", () => {
  fc.assert(
    fc.property(genSimpleAtom, genSimpleAtom, genSimpleAtom, (a, b, c) => {
      const src = `if ${a} then ${b} else ${c}`;
      const result = parseSource(src);
      return result.success && isIfExpr(result.value.statements[0]);
    }),
    { numRuns: 5000 }
  );
});
```

---

## Deferred Work

The following downstream updates are out of scope for this plan and will be addressed in separate plans:

- Formatter: new AST node types need formatting visit cases. Without this, the formatter will skip or crash on v2 constructs.
- Semantic analyzer: if one exists, it needs updating for new node types (variable resolution in closures, match arm patterns, etc.).
- LSP integration: hover, completion, and go-to-definition for new constructs (fn definitions, match arms, record fields) are deferred.
- Evaluator: the core IR, desugarer, and evaluator are separate plans that build on the parser's output.

---

## Implementation Checklist

- [ ] Phase 1 (atomic commit): Remove 4 AST types + guards, add 10 AST types + guards, update Expr union and Statement type; delete parser functions for Concat/Update/FileRef/VoiceRef and their lookaheads; rewire precedence chain (parsePipeline calls parseApplication); delete tests referencing removed types
- [ ] Phase 2: Add StringLiteral, AbcLiteralInline, and TuneSelector to atom dispatch and canStartAtom; add `peekAt` utility if needed
- [ ] Phase 3: Implement `parseOver()`, add OVER to atom dispatch and canStartAtom
- [ ] Phase 4: Implement `parseFnDef()`, `parseParamList()`, integrate `parseFnStatement()` into `parseStatement()`
- [ ] Phase 5: Implement `parseFnMatchDef()`, `parseMatchArms()`, `parseMatchArm()`, `parseCapture()`; arm body uses `parseApplication` (not `parsePipeline`)
- [ ] Phase 6: Implement `parseRecord()`, `parseRecordField()` with trailing comma support; add LBRACE to atom dispatch and canStartAtom
- [ ] Phase 7: Implement `parseLoad()`; add LOAD to atom dispatch and canStartAtom
- [ ] Phase 8: Implement `parseIf()`; add IF to atom dispatch and canStartAtom
- [ ] Phase 9: Add strategy keyword cases (TOPDOWN, BOTTOMUP, ONCETD, ALLTD) to atom dispatch and canStartAtom
- [ ] Phase 10: Update error recovery (add LBRACE/RBRACE to recovery points, implement `synchronizeMatchArm`, add closing-delimiter fallbacks)
- [ ] Phase 11: Update generators (remove obsolete, add new, update genExpr/genStatement/genIdentifier/genSimpleAtom)
- [ ] Phase 12: Add example-based tests for all new constructs, edge cases, and removal verification
- [ ] Phase 13: Add property-based tests for each new construct and integration-level program generation

Copy the plan file into the plans directory, and once you are done with the implementation of each phase, call the code review agent on the changes and address any feedback. After the feedback is addressed, verify that the build succeeds (`npm run build`) and all tests pass (`npm run test`). Only then commit the changes.
