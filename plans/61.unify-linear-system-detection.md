# Unify Linear System Boundary Detection

## Table of Contents

1. [Overview](#1-overview)
2. [Background](#2-background)
3. [Phase 1: Add Linear System Boundary Detection to Parser](#3-phase-1-add-linear-system-boundary-detection-to-parser)
4. [Phase 2: Update convertTuneToDeferred](#4-phase-2-update-converttunetodeferred)
5. [Affected Files Summary](#5-affected-files-summary)

---

## 1. Overview

This plan addresses an architectural inconsistency in system boundary detection between linear and deferred styles. Currently:

- Deferred-style: System boundaries are detected at parse time in `parseSystemsWithVoices()` via bar overlap analysis
- Linear-style: `parseSystemsWithVoices()` returns `[elements]` (everything as one system), and boundaries are detected later in `convertTuneToDeferred()` via `parseVoices()`

This inconsistency causes problems for downstream consumers (formatter, selectors) that expect correct system boundaries from the parser.

The fix: Make `parseSystemsWithVoices()` detect boundaries for both styles at parse time, so all downstream consumers receive correct `System[]` regardless of style.

---

## 2. Background

### System Boundary Detection Logic

Linear-style boundaries are detected by:
1. Voice order reversal: When a voice marker appears with a lower index than the previous voice (e.g., V:2 followed by V:1)
2. Implicit continuation: When a new music line appears without a voice marker

This logic exists in `parseVoices()` using `LinearVoiceCtx` and `isNewSystem()` in `voices2.ts`.

### Current Data Flow

1. Parser calls `parseSystemsWithVoices(elements, voices, linear)`
2. When `linear === true`, returns `[elements]` (no boundary detection)
3. Later, `convertTuneToDeferred()` calls `parseVoices()` to detect boundaries AND group by voice
4. `convertTuneToDeferred()` fills null voices and flattens to deferred style

### New Data Flow

1. Parser calls `parseSystemsWithVoices(elements, voices, linear)`
2. When `linear === true`, calls `buildLinearSystems()` to detect boundaries and return `System[]`
3. Later, `convertTuneToDeferred()` iterates over existing systems (boundaries already correct)
4. For each system, groups by voice, fills null voices, and flattens

---

## 3. Phase 1: Add Linear System Boundary Detection to Parser

### 3.1 New Function: buildLinearSystems

**File**: `parse/parsers/voices2.ts`

**Signature**:
```typescript
export function buildLinearSystems(
  elements: tune_body_code[],
  voices: string[]
): System[]
```

**Parameters**:
- `elements: tune_body_code[]` - The flat array of tune body elements (imported from `parse/types/Expr2.ts`)
- `voices: string[]` - The voice IDs from the tune header, in declaration order

**Returns**: `System[]` where each system contains elements in original input order

**Algorithm**:

This algorithm replicates the logic from `parseVoices()` in `voices2.ts` (lines 286-332), adapted to build `System[]` instead of `VoiceSequenceMap[]`.

```
systems: System[] = []
currentSystem: System = []
lastVoice = ""
atLineStart = false
sawMusicSinceVoiceMarker = false

for i = 0 to elements.length - 1:
  element = elements[i]

  if element is EOL token:
    currentSystem.push(element)
    atLineStart = true
    continue

  if element is voice marker:
    voiceId = extractVoiceId(element)

    if lastVoice == "":
      // First voice marker - no boundary check needed
      lastVoice = voiceId
    else:
      lastVoiceIndex = voices.indexOf(lastVoice)
      currentVoiceIndex = voices.indexOf(voiceId)

      // Handle dynamically discovered voice
      if currentVoiceIndex == -1:
        voices.push(voiceId)
        currentVoiceIndex = voices.length - 1

      // Voice order reversal - start new system
      if lastVoiceIndex > currentVoiceIndex:
        systems.push(currentSystem)
        currentSystem = []

      lastVoice = voiceId

    currentSystem.push(element)
    atLineStart = false
    sawMusicSinceVoiceMarker = false
    continue

  // Check for implicit system boundary (new music line without voice marker)
  // This matches parseVoices() lines 314-326
  // Guard: only create boundary if we have a valid lastVoice
  if atLineStart and sawMusicSinceVoiceMarker and isMusicExpr(element):
    lastVoiceIndex = voices.indexOf(lastVoice)
    if lastVoiceIndex >= 0:
      systems.push(currentSystem)
      currentSystem = []
    atLineStart = false
    sawMusicSinceVoiceMarker = true
  else if isMusicExpr(element):
    sawMusicSinceVoiceMarker = true
    atLineStart = false
  else if element is not WS token and element is not EOL token:
    atLineStart = false

  currentSystem.push(element)

// Don't forget last system
if currentSystem.length > 0:
  systems.push(currentSystem)

return systems
```

**Required imports** (already available in `voices2.ts`):
- `extractVoiceId` - from same file
- `isMusicExpr` - from `../helpers`
- `isVoiceMarker` - from `../helpers`
- `isToken` - from `../helpers`
- `TT` - from `./scan2`
- `tune_body_code`, `System` - from `../types/Expr2`

### 3.2 Modification to parseSystemsWithVoices

**File**: `parse/parsers/voices2.ts`

**Location**: Lines 553-556

**Current code**:
```typescript
export function parseSystemsWithVoices(elements: tune_body_code[], voices: string[] = [], linear: boolean = false): System[] {
  if (linear) {
    return [elements];
  }
  // ... rest of function
}
```

**New code**:
```typescript
export function parseSystemsWithVoices(elements: tune_body_code[], voices: string[] = [], linear: boolean = false): System[] {
  if (linear) {
    const voicesCopy = [...voices]; // Don't mutate the original
    return buildLinearSystems(elements, voicesCopy);
  }
  // ... rest of function unchanged
}
```

**Note on voice discovery**: `buildLinearSystems` may discover new voices (e.g., `V:3` when only `["1", "2"]` was declared) and adds them to the `voices` array it receives. We pass a copy to avoid mutating the original. In Phase 2, `convertTuneToDeferred` calls `getAllVoices(tune_body, tune.tune_header.voices)` which scans the tune body elements directly for voice markers, so it will discover all voices regardless of what happened during parsing. This means voice discovery does not need to be explicitly propagated between phases.

### 3.3 Tests

**File**: `parse/tests/voices2.spec.ts`

#### Unit tests for buildLinearSystems

Add a new describe block:

```typescript
describe("buildLinearSystems", () => {
  it("should return single system for empty elements", () => {
    const systems = buildLinearSystems([], []);
    expect(systems).to.have.lengthOf(0);
  });

  it("should return single system for single voice with single line", () => {
    const ctx = new ABCContext();
    const elements: tune_body_code[] = [
      new Info_line(ctx.generateId(), [createToken(TT.INF_HDR, "V:"), createToken(TT.INFO_STR, "1")]),
      createToken(TT.NOTE_LETTER, "C"),
      createToken(TT.EOL, "\n")
    ];
    const systems = buildLinearSystems(elements, ["1"]);
    expect(systems).to.have.lengthOf(1);
    expect(systems[0]).to.have.lengthOf(3);
  });

  it("should detect boundary on voice order reversal", () => {
    const ctx = new ABCContext();
    const elements: tune_body_code[] = [
      new Info_line(ctx.generateId(), [createToken(TT.INF_HDR, "V:"), createToken(TT.INFO_STR, "1")]),
      createToken(TT.NOTE_LETTER, "C"),
      createToken(TT.EOL, "\n"),
      new Info_line(ctx.generateId(), [createToken(TT.INF_HDR, "V:"), createToken(TT.INFO_STR, "2")]),
      createToken(TT.NOTE_LETTER, "D"),
      createToken(TT.EOL, "\n"),
      new Info_line(ctx.generateId(), [createToken(TT.INF_HDR, "V:"), createToken(TT.INFO_STR, "1")]),
      createToken(TT.NOTE_LETTER, "E"),
      createToken(TT.EOL, "\n")
    ];
    const systems = buildLinearSystems(elements, ["1", "2"]);
    expect(systems).to.have.lengthOf(2);
  });

  it("should detect implicit boundary on new music line", () => {
    const ctx = new ABCContext();
    const elements: tune_body_code[] = [
      new Info_line(ctx.generateId(), [createToken(TT.INF_HDR, "V:"), createToken(TT.INFO_STR, "1")]),
      createToken(TT.NOTE_LETTER, "C"),
      createToken(TT.EOL, "\n"),
      createToken(TT.NOTE_LETTER, "D"),
      createToken(TT.EOL, "\n")
    ];
    const systems = buildLinearSystems(elements, ["1"]);
    expect(systems).to.have.lengthOf(2);
  });

  it("should handle dynamically discovered voices", () => {
    const ctx = new ABCContext();
    const elements: tune_body_code[] = [
      new Info_line(ctx.generateId(), [createToken(TT.INF_HDR, "V:"), createToken(TT.INFO_STR, "1")]),
      createToken(TT.NOTE_LETTER, "C"),
      createToken(TT.EOL, "\n"),
      new Info_line(ctx.generateId(), [createToken(TT.INF_HDR, "V:"), createToken(TT.INFO_STR, "3")]),
      createToken(TT.NOTE_LETTER, "D"),
      createToken(TT.EOL, "\n"),
      new Info_line(ctx.generateId(), [createToken(TT.INF_HDR, "V:"), createToken(TT.INFO_STR, "1")]),
      createToken(TT.NOTE_LETTER, "E"),
      createToken(TT.EOL, "\n")
    ];
    const voices = ["1", "2"];
    const systems = buildLinearSystems(elements, voices);
    expect(systems).to.have.lengthOf(2);
    expect(voices).to.include("3"); // Voice 3 was discovered
  });

  it("should preserve element order within each system", () => {
    const ctx = new ABCContext();
    const v1 = new Info_line(ctx.generateId(), [createToken(TT.INF_HDR, "V:"), createToken(TT.INFO_STR, "1")]);
    const noteC = createToken(TT.NOTE_LETTER, "C");
    const eol1 = createToken(TT.EOL, "\n");
    const v2 = new Info_line(ctx.generateId(), [createToken(TT.INF_HDR, "V:"), createToken(TT.INFO_STR, "2")]);
    const noteD = createToken(TT.NOTE_LETTER, "D");
    const eol2 = createToken(TT.EOL, "\n");

    const elements: tune_body_code[] = [v1, noteC, eol1, v2, noteD, eol2];
    const systems = buildLinearSystems(elements, ["1", "2"]);

    expect(systems).to.have.lengthOf(1);
    expect(systems[0][0]).to.equal(v1);
    expect(systems[0][1]).to.equal(noteC);
    expect(systems[0][2]).to.equal(eol1);
    expect(systems[0][3]).to.equal(v2);
  });
});
```

#### Tests for parseSystemsWithVoices with linear=true

Add to the existing `parseSystemsWithVoices` describe block:

```typescript
it("should return correct systems for linear=true", () => {
  const sample = `X:1
K:C
V:1
C|D|
V:2
E|F|
V:1
G|A|`;

  const ctx = new ABCContext();
  ctx.tuneLinear = true;
  const tokens = Scanner(sample, ctx);
  const parseCtx = new ParseCtx(tokens, ctx);
  const tune = parseTune(parseCtx);

  expect(tune.tune_body?.sequence).to.have.lengthOf(2);
});

it("should preserve element order for linear=true", () => {
  const sample = `X:1
K:C
V:1
C|
V:2
D|`;

  const ctx = new ABCContext();
  ctx.tuneLinear = true;
  const tokens = Scanner(sample, ctx);
  const parseCtx = new ParseCtx(tokens, ctx);
  const tune = parseTune(parseCtx);

  expect(tune.tune_body?.sequence).to.have.lengthOf(1);
  // Verify V:1 appears before V:2 in the system
  const system = tune.tune_body!.sequence[0];
  let foundV1 = false;
  let foundV2 = false;
  let v1Index = -1;
  let v2Index = -1;

  for (let i = 0; i < system.length; i++) {
    if (isVoiceMarker(system[i])) {
      const id = extractVoiceId(system[i] as Info_line);
      if (id === "1") { foundV1 = true; v1Index = i; }
      if (id === "2") { foundV2 = true; v2Index = i; }
    }
  }

  expect(foundV1).to.be.true;
  expect(foundV2).to.be.true;
  expect(v1Index).to.be.lessThan(v2Index);
});
```

### 3.4 To Do List

- Add `buildLinearSystems()` function to `parse/parsers/voices2.ts`
- Modify `parseSystemsWithVoices()` to call `buildLinearSystems()` when `linear === true`
- Export `buildLinearSystems` from `parse/parsers/voices2.ts` (for testing)
- Add unit tests for `buildLinearSystems()` in `parse/tests/voices2.spec.ts`
- Add tests for `parseSystemsWithVoices(..., linear=true)` in `parse/tests/voices2.spec.ts`
- Run `npm run test` to verify all tests pass
- Run `npm run build` to verify build passes
- Final verification: build and tests both pass
- Call the code review agent. Address any feedback.
- Commit once the build passes and all tests pass.

---

## 4. Phase 2: Update convertTuneToDeferred

### 4.1 New Function: systemToVoiceMap

**File**: `parse/abcl/AbclToAbcConverter.ts`

**Signature**:
```typescript
function systemToVoiceMap(
  system: System,
  allVoices: string[],
  ctx: ABCContext
): { map: VoiceSequenceMap; prefix: tune_body_code[] }
```

**Parameters**:
- `system: System` - A single system (flat array of tune_body_code), imported from `parse/types/Expr2.ts`
- `allVoices: string[]` - All known voice IDs across the tune
- `ctx: ABCContext` - The ABC context, imported from `parse/parsers/Context.ts`

**Returns**: Object with:
- `map: VoiceSequenceMap` - Map of voice ID to elements for that voice (imported from `parse/parsers/voices2.ts`)
- `prefix: tune_body_code[]` - Elements before the first voice marker

**Algorithm**:
```
map = new Map<string, tune_body_code[] | null>()
prefix: tune_body_code[] = []
currentVoice = ""
currentSequence: tune_body_code[] = []

// Initialize map with null for all known voices
for voice in allVoices:
  map.set(voice, null)

for element in system:
  if element is voice marker:
    // Save current sequence if we were in a voice
    if currentVoice != "":
      existing = map.get(currentVoice)
      if existing:
        existing.push(...currentSequence)
      else:
        map.set(currentVoice, currentSequence)

    currentVoice = extractVoiceId(element)
    currentSequence = [element]

    // Handle dynamically discovered voice
    if not map.has(currentVoice):
      map.set(currentVoice, null)
      allVoices.push(currentVoice)

    continue

  if currentVoice == "":
    // Content before first voice marker
    prefix.push(element)
  else:
    currentSequence.push(element)

// Save final voice sequence
if currentVoice != "" and currentSequence.length > 0:
  existing = map.get(currentVoice)
  if existing:
    existing.push(...currentSequence)
  else:
    map.set(currentVoice, currentSequence)

return { map, prefix }
```

**Required imports** (most already available in file):
- `extractVoiceId` - from `../parsers/voices2`
- `isVoiceMarker` - from `../helpers`
- `VoiceSequenceMap` - from `../parsers/voices2`
- `System`, `tune_body_code` - from `../types/Expr2`
- `ABCContext` - from `../parsers/Context`

### 4.2 Modified convertTuneToDeferred

**File**: `parse/abcl/AbclToAbcConverter.ts`

**Location**: Lines 250-292

**Current code**:
```typescript
export function convertTuneToDeferred(tune: Tune, ctx: ABCContext): Tune {
  const tune_body = tune.tune_body;
  if (!tune_body || tune_body.sequence.length === 0) {
    return tune;
  }

  // In linear mode, the parser returns a single system with all elements
  const allElements = tune_body.sequence[0];
  const vxls = getAllVoices(tune_body, tune.tune_header.voices);
  // Parse into map-based structure using LinearVoiceCtx
  const linearCtx = new LinearVoiceCtx(allElements, vxls);
  parseVoices(linearCtx);

  // If no systems (no voice markers found), return as-is
  if (linearCtx.systems.length === 0) {
    return tune;
  }

  // Get the complete voice list from the context
  const allVoices = linearCtx.voices;

  // If only one voice, no conversion needed
  if (allVoices.length <= 1) {
    return tune;
  }

  // Process each system: fill null entries and flatten
  const processedSystems: System[] = [];

  for (const systemMap of linearCtx.systems) {
    fillNullVoices(systemMap, allVoices, ctx);
    const flatSystem = flattenSystemMap(systemMap, allVoices, ctx);
    processedSystems.push(flatSystem);
  }

  // Prepend prefix to the first system
  if (linearCtx.prefix.length > 0 && processedSystems.length > 0) {
    processedSystems[0] = [...linearCtx.prefix, ...processedSystems[0]];
  }

  const newTuneBody = new Tune_Body(ctx.generateId(), processedSystems);
  return new Tune(ctx.generateId(), tune.tune_header, newTuneBody);
}
```

**New code**:
```typescript
export function convertTuneToDeferred(tune: Tune, ctx: ABCContext): Tune {
  const tune_body = tune.tune_body;
  if (!tune_body || tune_body.sequence.length === 0) {
    return tune;
  }

  const allVoices = getAllVoices(tune_body, tune.tune_header.voices);

  // If only one voice, no conversion needed
  if (allVoices.length <= 1) {
    return tune;
  }

  const processedSystems: System[] = [];
  let globalPrefix: tune_body_code[] = [];

  for (let i = 0; i < tune_body.sequence.length; i++) {
    const system = tune_body.sequence[i];

    // Convert system to voice map (grouping only, boundaries already correct)
    const { map: systemMap, prefix } = systemToVoiceMap(system, allVoices, ctx);

    // Collect prefix from first system only
    if (i === 0 && prefix.length > 0) {
      globalPrefix = prefix;
    }

    // Skip empty systems (no voice markers found)
    if (systemMap.size === 0) {
      continue;
    }

    // Fill null voices with silenced content
    fillNullVoices(systemMap, allVoices, ctx);

    // Flatten to deferred style
    const flatSystem = flattenSystemMap(systemMap, allVoices, ctx);
    processedSystems.push(flatSystem);
  }

  // If no systems were processed, return as-is
  if (processedSystems.length === 0) {
    return tune;
  }

  // Prepend global prefix to the first system
  if (globalPrefix.length > 0) {
    processedSystems[0] = [...globalPrefix, ...processedSystems[0]];
  }

  const newTuneBody = new Tune_Body(ctx.generateId(), processedSystems);
  return new Tune(ctx.generateId(), tune.tune_header, newTuneBody);
}
```

### 4.3 Cleanup

Remove unused imports from `AbclToAbcConverter.ts` if no longer needed:
- `LinearVoiceCtx` - check if used elsewhere in file
- `parseVoices` - check if used elsewhere in file

Update the file header comment (lines 1-8) to reflect the new behavior:
```typescript
/**
 * AbclToAbcConverter - Converts ABCL (linear style) to ABC (deferred style)
 *
 * In linear style, voice markers act as headers for subsequent content lines.
 * The parser now provides correct system boundaries. This converter iterates
 * over each system, groups elements by voice into a map-based structure,
 * fills null entries with silenced content, and flattens to deferred style.
 */
```

### 4.4 Tests

**File**: `parse/tests/abcl2abc.spec.ts`

#### Verify existing tests still pass

Existing tests should continue to work because the output format is unchanged.

#### Add tests for multi-system input

```typescript
describe("convertTuneToDeferred with pre-split systems", () => {
  it("should process each system independently", () => {
    const sample = `X:1
K:C
V:1
C|D|
V:2
E|F|
V:1
G|A|`;

    const ctx = new ABCContext();
    ctx.tuneLinear = true;
    const tokens = Scanner(sample, ctx);
    const parseCtx = new ParseCtx(tokens, ctx);
    const tune = parseTune(parseCtx);

    // After Phase 1, tune should have 2 systems
    expect(tune.tune_body?.sequence).to.have.lengthOf(2);

    // Convert to deferred
    const converted = convertTuneToDeferred(tune, ctx);

    // Should still have 2 systems
    expect(converted.tune_body?.sequence).to.have.lengthOf(2);
  });

  it("should fill null voices per system independently", () => {
    const sample = `X:1
K:C
V:1
C|D|
V:2
E|F|
V:1
G|A|`;

    const ctx = new ABCContext();
    ctx.tuneLinear = true;
    const tokens = Scanner(sample, ctx);
    const parseCtx = new ParseCtx(tokens, ctx);
    const tune = parseTune(parseCtx);
    const converted = convertTuneToDeferred(tune, ctx);

    // Verify second system has both V:1 and V:2
    const system2 = converted.tune_body?.sequence[1];
    const voiceMarkers = system2?.filter(el => isVoiceMarker(el));
    const voiceIds = voiceMarkers?.map(el => extractVoiceId(el as Info_line));

    expect(voiceIds).to.include("1");
    expect(voiceIds).to.include("2");
  });

  it("should preserve prefix from first system only", () => {
    const sample = `X:1
K:C
% comment before voices
V:1
C|D|
V:2
E|F|
V:1
G|A|`;

    const ctx = new ABCContext();
    ctx.tuneLinear = true;
    const tokens = Scanner(sample, ctx);
    const parseCtx = new ParseCtx(tokens, ctx);
    const tune = parseTune(parseCtx);
    const converted = convertTuneToDeferred(tune, ctx);

    // Verify comment appears in first system
    const system1 = converted.tune_body?.sequence[0];
    const hasComment = system1?.some(el =>
      el instanceof Token && el.type === TT.COMMENT
    );
    expect(hasComment).to.be.true;

    // Verify comment does not appear in second system
    const system2 = converted.tune_body?.sequence[1];
    const hasCommentInSystem2 = system2?.some(el =>
      el instanceof Token && el.type === TT.COMMENT
    );
    expect(hasCommentInSystem2).to.be.false;
  });
});
```

### 4.5 To Do List

- Add `systemToVoiceMap()` function to `parse/abcl/AbclToAbcConverter.ts`
- Modify `convertTuneToDeferred()` to iterate over existing systems and use `systemToVoiceMap()`
- Remove unused imports (`LinearVoiceCtx`, `parseVoices`) if no longer needed
- Update file header comment to reflect new behavior
- Run existing tests in `parse/tests/abcl2abc.spec.ts` to verify they still pass
- Add new tests for multi-system input handling
- Run `npm run test` to verify all tests pass
- Run `npm run build` to verify build passes
- Final verification: build and tests both pass
- Call the code review agent. Address any feedback.
- Commit once the build passes and all tests pass.

---

## 5. Affected Files Summary

| File | Changes |
|------|---------|
| `parse/parsers/voices2.ts` | Add `buildLinearSystems()`, modify `parseSystemsWithVoices()` |
| `parse/tests/voices2.spec.ts` | Add tests for `buildLinearSystems()` and `parseSystemsWithVoices(..., linear=true)` |
| `parse/abcl/AbclToAbcConverter.ts` | Add `systemToVoiceMap()`, modify `convertTuneToDeferred()`, update imports and comments |
| `parse/tests/abcl2abc.spec.ts` | Add tests for multi-system input handling |

---

Copy the plan file into the plans directory, and once you are done with the implementation of each of the phases of the plan, make sure to call the code review agent on the current phase and address any feedback that the code review agent might have. After you are done with the feedback and all the tests are passing, commit the changes and then move onto the next phase. Do this until finished.
